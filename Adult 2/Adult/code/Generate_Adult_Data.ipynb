{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from cvxpy import *\n",
    "from DTools3 import *\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.patches import Rectangle\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "\n",
    "Import the adult dataset, and name categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataFolder = '../data/'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    dataFolder + \"adult.data\",\n",
    "    names=[\n",
    "        \"Age\", \"Workclass\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Martial Status\",\n",
    "        \"Occupation\", \"Relationship\", \"Race\", \"Gender\", \"Capital Gain\", \"Capital Loss\",\n",
    "        \"Hours per week\", \"Country\", \"Income\"],\n",
    "        na_values=\"?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32561, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group age by decade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Age (decade)'] = df['Age'].apply(lambda x: np.floor(x/10.0)*10.0)\n",
    "df['Age (decade)'] = df['Age'].apply(lambda x: np.floor(x/10.0)*10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster minority, education and age attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_edu(x):\n",
    "    if x<=5:\n",
    "        return '<6'\n",
    "    elif x>=13:\n",
    "        return '>12'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def age_cut(x):\n",
    "    if x>=70:\n",
    "        return '>=70'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# Limit education range\n",
    "df['Education Years'] = df['Education-Num'].apply(lambda x : group_edu(x))\n",
    "\n",
    "# Limit age range\n",
    "df['Age (decade)'] = df['Age (decade)'].apply(lambda x : age_cut(x))\n",
    "\n",
    "# Transform all that is non-white into 'minority'\n",
    "df['Race'] = df['Race'].apply(lambda x: x if x== ' White' else 'Minority')\n",
    "\n",
    "# Add binary income variable\n",
    "df['Income Binary'] = df['Income'].apply(lambda x : 1 if x == \" >50K\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be interested only in age, education, income, gender and race. Set discriminatory features (`D_features`), binary response variable (`Y_features`) and decision features (`X_features`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features = ['Age (decade)','Education Years','Income','Gender','Race','Income Binary']\n",
    "features = ['Age (decade)','Education Years','Income','Gender','Income Binary']\n",
    "#D_features = ['Gender','Race']\n",
    "D_features = ['Gender']\n",
    "Y_features = ['Income Binary']\n",
    "X_features = ['Age (decade)', 'Education Years']\n",
    "\n",
    "# keep only the features we will use\n",
    "df = df[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we do a 80-20 split of the data. The random number generator seed is fixed, so this should generate consistent splits. We automatically rename output files accordingly. Pairs of train and test dataset are stored in `df_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "rs = ShuffleSplit(n_splits=5, test_size=.2, random_state=888)  ### CHANGE SEED FOR DIFFERENT SPLITS!\n",
    "df_list = []\n",
    "for train_index,test_index in rs.split(df):\n",
    "    df_list.append((df.iloc[train_index,:].copy(),df.iloc[test_index,:].copy()))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we set the distortion metric. This function will receive the two dictionary of features X and Y corresponding to the new and old values. You may want to adjust the penalties for different results. The events that receive `bad_val` are those that will never happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Dclass():\n",
    "# adjust education\n",
    "    def adjustEdu(self,v):\n",
    "        if v=='>12':\n",
    "            return 13\n",
    "        elif v=='<6':\n",
    "            return 5\n",
    "        else:\n",
    "            return v\n",
    "\n",
    "    def adjustAge(self,a):\n",
    "        if a == '>=70':\n",
    "            return 70.0\n",
    "        else:\n",
    "            return a\n",
    "\n",
    "    # distortion metric\n",
    "    def getDistortion(self,vold,vnew):\n",
    "        '''\n",
    "        Distortion metric.\n",
    "\n",
    "        Inputs:\n",
    "        *vold : dictionary of the form {attr:value} with old values\n",
    "        *vnew : dictionary of the form {attr:value} with new values\n",
    "\n",
    "        Output\n",
    "        *d : distortion value\n",
    "        '''\n",
    "\n",
    "        # value that will be returned for events that should not occur\n",
    "        bad_val = 3.0\n",
    "\n",
    "\n",
    "        # Adjust education years\n",
    "        eOld = self.adjustEdu(vold['Education Years'])\n",
    "        eNew = self.adjustEdu(vnew['Education Years'])\n",
    "\n",
    "        # Education cannot be lowered or increased in more than 1 year\n",
    "        if (eNew<eOld)| (eNew>eOld+1):\n",
    "            return bad_val\n",
    "\n",
    "        # adjust age\n",
    "        aOld = self.adjustAge(vold['Age (decade)'])\n",
    "        aNew = self.adjustAge(vnew['Age (decade)'])\n",
    "\n",
    "        # Age cannot be increased or decreased in more than a decade\n",
    "        if np.abs(aOld-aNew)>10.0:\n",
    "            return bad_val\n",
    "        \n",
    "        # Penalty of 2 if age is decreased or increased\n",
    "        if np.abs(aOld-aNew)>0:\n",
    "            return 2.0\n",
    "\n",
    "        # final penalty according to income\n",
    "        if vold['Income Binary']>vnew['Income Binary']:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.0\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we adjust the cost constraints. For the adult dataset, we control the probability of certain mappings happening. You may not want to change this now, since it matches the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c1 = .99 # value of (delta1,c1): to keep.\n",
    "c2 = 1.99  # value of (delta2,c2): value that should no happen\n",
    "c3 = 2.99 # penalty for adjusting age\n",
    "clist = [c1,c2, c3]\n",
    "Dclass = Dclass()\n",
    "\n",
    "DT = DTools(df=df,features=features)\n",
    "\n",
    "# Set features\n",
    "DT.setFeatures(D=D_features,X=X_features,Y=Y_features)\n",
    "\n",
    "# Set Distortion\n",
    "DT.setDistortion(Dclass,clist=clist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next code is important -- it can help you explore values of constraints that will not lead to infeasible solutions. Dlist constrols distortion (see more info below). The red region is infeasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]DTools3.py:235: RuntimeWarning: divide by zero encountered in reciprocal\n",
      "  Pxy_xhyh = np.nan_to_num(np.diag(PxyMarginal**(-1))).dot(self.dfMask_Pxyd_to_Pxy.values.T).dot(np.diag(PxydMarginal))*Pmap\n",
      "100%|██████████| 10/10 [00:10<00:00,  1.13s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq8AAAFHCAYAAACPnqXvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nymDxSkRERERTBotXIiIiIpoy/j/hQMeOs0P5gAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3be71c8cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dlist = [.1,0.05,0]\n",
    "#dlist = [.2,0.15,0.05]\n",
    "\n",
    "\n",
    "\n",
    "epsilonV = np.linspace(0,.5,10)\n",
    "y = np.zeros(len(epsilonV))\n",
    "z = np.zeros(len(epsilonV))\n",
    "\n",
    "for i in tqdm(range(len(epsilonV))):\n",
    "    try:\n",
    "        DT.optimize(epsilon=epsilonV[i],dlist = dlist,verbose=False)\n",
    "    except:\n",
    "        y[i] = np.inf\n",
    "        z[i] = np.inf\n",
    "        continue\n",
    "        \n",
    "    y[i] = DT.optimum\n",
    "    z[i] = DT.const[0]\n",
    "    \n",
    "# Plot\n",
    "sns.set(font_scale=1.8,font='sans-serif')\n",
    "plt.figure(figsize = (10,5))\n",
    "ax = plt.plot(epsilonV,y,'-',linewidth=2)\n",
    "plt.ylabel(\"Objective Value\")\n",
    "plt.xlabel(\"$\\epsilon$\")\n",
    "plt.title(\"Objective vs. $\\epsilon$\")# for\\n$\\delta_1 =$\"+str(dlist[0])+\", $\\delta_2=$\"+str(dlist[1])+\" and $\\delta_3=$\"+str(dlist[2]))\n",
    "infeasible = np.where(y==np.inf)[0]\n",
    "if infeasible:\n",
    "    plt.axvspan(0, epsilonV[infeasible[-1]+1], color='red', alpha=0.2)\n",
    "plt.xlim([epsilonV.min(),epsilonV.max()])\n",
    "plt.ylim([-0.0002,y[y<np.inf].max()+0.0001])\n",
    "\n",
    "#plt.text(0.05, 0.0075, r'Infeasible', fontsize=20)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the values you may want to change. dlist has three parameters that control distortion. The last one should be left at 0, but the first two can be tweeked (as long as dlist[0]$\\geq$dlist[1]). We use the same distortion across protected varialbes.\n",
    "\n",
    "The second value is the discrimination constraint. I would leave it at .20 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these were the values used in the paper\n",
    "# dlist = [.1,0.05,0]\n",
    "# epsilon = .2\n",
    "\n",
    "#dlist = [.15,0.1,0]\n",
    "#epsilon = .09\n",
    "\n",
    "dlist = [.1,0.05,0]\n",
    "epsilon = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an auxiliary function for helping in randomizing the dataset. It receives a dataset and a mapping, and randomizes accordingly. I'm fixing the value of the seed for numpy -- you may want to change this in order to produce fresh datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######### CHANGE SEED HERE ###########\n",
    "seed = sum([ord(b) for b in 'Bhanu'])\n",
    "np.random.seed(seed = seed)\n",
    "####################################\n",
    "\n",
    "def randomize(df, dfMap,features=[]):\n",
    "    df2 = df.copy()\n",
    "    print('Randomizing...')\n",
    "    for idx in tqdm(df2.index):\n",
    "        rowTest = df2.loc[idx,:]\n",
    "        vals = rowTest[features]\n",
    "        draw = dfMap.loc[tuple(vals.tolist())]\n",
    "        #randomly select value\n",
    "\n",
    "        mapVal = np.random.choice(range(len(draw)),p=draw.tolist())\n",
    "        draw.index[mapVal]\n",
    "        df2.loc[idx,draw.index.names] = draw.index[mapVal]\n",
    "        \n",
    "    return df2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main loop\n",
    "\n",
    "This is where the brute of the work will be done. May take a while to run, and will print randomization progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Current split: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhanu/anaconda3/envs/python2/lib/python2.7/site-packages/pandas/core/base.py:324: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  return self.obj.drop(self.exclusions, axis=1)\n",
      "  0%|          | 33/26048 [00:00<01:19, 327.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing training set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26048/26048 [01:16<00:00, 339.56it/s]\n",
      "  1%|          | 52/6513 [00:00<00:12, 519.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing test set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 582/6513 [00:01<00:11, 527.95it/s]/home/bhanu/anaconda3/envs/python2/lib/python2.7/site-packages/ipykernel/__main__.py:15: RuntimeWarning: invalid value encountered in less\n",
      "100%|██████████| 6513/6513 [00:11<00:00, 546.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Current split: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/26048 [00:00<01:20, 322.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing training set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26048/26048 [01:14<00:00, 351.68it/s]\n",
      "  1%|          | 52/6513 [00:00<00:12, 516.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing test set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6513/6513 [00:12<00:00, 540.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Current split: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/26048 [00:00<01:20, 323.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing training set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26048/26048 [01:14<00:00, 347.89it/s]\n",
      "  1%|          | 53/6513 [00:00<00:12, 526.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing test set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6513/6513 [00:12<00:00, 541.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Current split: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 33/26048 [00:00<01:20, 322.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing training set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26048/26048 [01:15<00:00, 345.49it/s]\n",
      "  1%|          | 50/6513 [00:00<00:13, 492.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing test set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6513/6513 [00:12<00:00, 536.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "Current split: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 32/26048 [00:00<01:22, 314.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing training set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26048/26048 [01:20<00:00, 323.52it/s]\n",
      "  1%|          | 53/6513 [00:00<00:12, 526.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing test set...\n",
      "Randomizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6513/6513 [00:11<00:00, 543.16it/s]\n"
     ]
    }
   ],
   "source": [
    "result_folder = '../experiment_data1/'\n",
    "split_num = 0\n",
    "\n",
    "# iterate over pairs\n",
    "for (df_train,df_test) in df_list:\n",
    "    file_name = str(split_num)\n",
    "    \n",
    "    print('-----------------')\n",
    "    print('Current split: '+file_name)\n",
    "\n",
    "    # initialize a new DT object\n",
    "    DT = DTools(df=df_train,features=features)\n",
    "\n",
    "    # Set features\n",
    "    DT.setFeatures(D=D_features,X=X_features,Y=Y_features)\n",
    "\n",
    "    # Set Distortion\n",
    "    DT.setDistortion(Dclass,clist=clist)\n",
    "\n",
    "    # solve optimization for previous parameters -- This uses and older implementation, based on the FATML submission.\n",
    "    DT.optimize(epsilon=epsilon,dlist = dlist,verbose=False)\n",
    "\n",
    "    DT.computeMarginals()\n",
    "\n",
    "    # randomized mapping for training\n",
    "    # this is the dataframe with the randomization for the train set\n",
    "    dfPtrain = DT.dfP.applymap(lambda x : 0 if x<1e-8 else x)\n",
    "    dfPtrain = dfPtrain.divide(dfPtrain.sum(axis=1),axis=0)\n",
    "\n",
    "    # randomized mapping for testing (Beware of ugly code)\n",
    "    d1 = DT.dfFull.reset_index().groupby(D_features+X_features).sum()\n",
    "    d2 = d1.transpose().reset_index().groupby(X_features).sum()\n",
    "    dTest = d2.transpose()\n",
    "    dTest = dTest.drop(Y_features,1)\n",
    "    dTest = dTest.applymap(lambda x: x if x>1e-8 else 0)\n",
    "    dTest = dTest/dTest.sum()\n",
    "\n",
    "    # this is the dataframe with the randomization for the test set\n",
    "    dfPtest = dTest.divide(dTest.sum(axis=1),axis=0)\n",
    "\n",
    "    # Randomize train data\n",
    "    print('Randomizing training set...')\n",
    "    df_train_new = randomize(df_train,dfPtrain,features = D_features+X_features+Y_features)\n",
    "\n",
    "    # Randomize test data\n",
    "    print('Randomizing test set...')\n",
    "    df_test_new = randomize(df_test,dfPtest,features = D_features+X_features)\n",
    "\n",
    "    # Save train files\n",
    "    df_train.to_csv(result_folder+'train_'+file_name+'.csv')\n",
    "    df_train_new.to_csv(result_folder+'train_new_'+file_name+'.csv')\n",
    "\n",
    "    # Save test files\n",
    "    df_test.to_csv(result_folder+'test_'+file_name+'.csv')\n",
    "    df_test_new.to_csv(result_folder+'test_new_'+file_name+'.csv')\n",
    "    \n",
    "    # increment split number\n",
    "    split_num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "LogReg original data (with disc. variable):\n",
      "Train performance: (original dataset)\n",
      "0.802902334152\n",
      "Test performance (original dataset): \n",
      "0.807615538154\n",
      "Test classification result:\n",
      "Gender\n",
      " Female    0.111410\n",
      " Male      0.304762\n",
      "Name: pred, dtype: float64\n",
      "----------------------------------------------------------------\n",
      "LogReg on perturbed data:\n",
      "Train performance (pert. dataset): \n",
      "0.767122235872\n",
      "Gender\n",
      " Female    0.256933\n",
      " Male      0.268406\n",
      "Name: pred, dtype: float64\n",
      "Train discrimination ratios result:\n",
      "Gender     Female      Male\n",
      "Gender                     \n",
      " Female  1.000000  0.957254\n",
      " Male    1.044655  1.000000\n",
      "Perturbed test performance when scored on original test y variable: \n",
      "0.773069246123\n",
      "Test classification result:\n",
      "Gender\n",
      " Female    0.271147\n",
      " Male      0.271364\n",
      "Name: pred, dtype: float64\n",
      "Test discrimination ratios result:\n",
      "Gender     Female      Male\n",
      "Gender                     \n",
      " Female  1.000000  0.999202\n",
      " Male    1.000799  1.000000\n",
      "----------------------------------------------------------------\n",
      "LogReg original data (DROPPING disc. variable):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhanu/anaconda3/envs/python2/lib/python2.7/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping D train performance: \n",
      "0.785741707617\n",
      "Gender\n",
      " Female    0.214838\n",
      " Male      0.255676\n",
      "Name: pred, dtype: float64\n",
      "Train discrimination ratios result:\n",
      "Gender    Female      Male\n",
      "Gender                    \n",
      " Female  1.00000  0.840272\n",
      " Male    1.19009  1.000000\n",
      "Dropping D test performance: \n",
      "0.790265622601\n",
      "Test classification result:\n",
      "Gender\n",
      " Female    0.214587\n",
      " Male      0.254118\n",
      "Name: pred, dtype: float64\n",
      "Test discrimination ratios result:\n",
      "Gender     Female      Male\n",
      "Gender                     \n",
      " Female  1.000000  0.844439\n",
      " Male    1.184217  1.000000\n",
      "----------------------------------------------------------------\n",
      "LogReg perturbed data (DROPPING disc. variable):\n",
      "Dropping D train performance: \n",
      "0.78363022113\n",
      "Gender\n",
      " Female    0.242450\n",
      " Male      0.275557\n",
      "Name: pred, dtype: float64\n",
      "Dropping D test performance: \n",
      "0.776293566713\n",
      "Test classification result:\n",
      "Gender\n",
      " Female    0.256349\n",
      " Male      0.278693\n",
      "Name: pred, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# original performance on train data\n",
    "print '----------------------------------------------------------------'\n",
    "print 'LogReg original data (with disc. variable):'\n",
    "rf = LogisticRegression()\n",
    "dft = pd.get_dummies(df_train[D_features+X_features])\n",
    "rf.fit(dft,df_train[Y_features])\n",
    "print 'Train performance: (original dataset)'\n",
    "print rf.score(dft,df_train[Y_features])\n",
    "\n",
    "# df_train_pred = df_train\n",
    "# df_train_pred['pred'] = rf.predict(dft)\n",
    "\n",
    "# # prediction per class\n",
    "# print df_train_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "dft = pd.get_dummies(df_test[D_features+X_features])\n",
    "print 'Test performance (original dataset): '\n",
    "print rf.score(dft,df_test[Y_features])\n",
    "\n",
    "print 'Test classification result:'\n",
    "# save performance\n",
    "df_test_pred = df_test\n",
    "df_test_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print df_test_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "\n",
    "\n",
    "print '----------------------------------------------------------------'\n",
    "print 'LogReg on perturbed data:'\n",
    "\n",
    "# performance on perturbed train data\n",
    "rf = LogisticRegression()\n",
    "dft = pd.get_dummies(df_train_new[D_features+X_features])\n",
    "rf.fit(dft,df_train_new[Y_features])\n",
    "print 'Train performance (pert. dataset): '\n",
    "print rf.score(dft,df_train_new[Y_features])\n",
    "\n",
    "df_train_pred = df_train_new\n",
    "df_train_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "print df_train_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "print 'Train discrimination ratios result:'\n",
    "mean = df_train_pred.groupby(D_features)['pred'].mean()\n",
    "v = mean.values\n",
    "v = v.reshape(len(v),1)\n",
    "ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "print ratio_df\n",
    "\n",
    "# performance on perturbed train data compared to original train data\n",
    "#rf = RandomForestClassifier()\n",
    "#dft = pd.get_dummies(df_train_new[D_features+X_features])\n",
    "#rf.fit(dft,df_train_new[Y_features])\n",
    "dft = pd.get_dummies(df_test_new[D_features+X_features])\n",
    "print 'Perturbed test performance when scored on original test y variable: '\n",
    "print rf.score(dft,df_test[Y_features])\n",
    "\n",
    "dft = pd.get_dummies(df_test_new[D_features+X_features])\n",
    "# save performance\n",
    "df_test_pred = df_test_new\n",
    "df_test_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print 'Test classification result:'\n",
    "print df_test_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "# test discrimination ratios\n",
    "# This is what pyhgd will look like for y=1\n",
    "print 'Test discrimination ratios result:'\n",
    "mean = df_test_pred.groupby(D_features)['pred'].mean()\n",
    "v = mean.values\n",
    "v = v.reshape(len(v),1)\n",
    "ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "print ratio_df\n",
    "\n",
    "\n",
    "# compared to dropping feature\n",
    "print '----------------------------------------------------------------'\n",
    "print 'LogReg original data (DROPPING disc. variable):'\n",
    "rf = LogisticRegression()\n",
    "dft = pd.get_dummies(df_train[X_features])\n",
    "rf.fit(dft,df_train[Y_features])\n",
    "print 'Dropping D train performance: '\n",
    "print rf.score(dft,df_train[Y_features])\n",
    "\n",
    "df_train_pred = df_train\n",
    "df_train_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print df_train_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "print 'Train discrimination ratios result:'\n",
    "mean = df_train_pred.groupby(D_features)['pred'].mean()\n",
    "v = mean.values\n",
    "v = v.reshape(len(v),1)\n",
    "ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "print ratio_df\n",
    "\n",
    "dft = pd.get_dummies(df_test[X_features])\n",
    "print 'Dropping D test performance: '\n",
    "print rf.score(dft,df_test[Y_features])\n",
    "print 'Test classification result:'\n",
    "# save performance\n",
    "df_test_pred = df_test\n",
    "df_test_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print df_test_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "print 'Test discrimination ratios result:'\n",
    "mean = df_test_pred.groupby(D_features)['pred'].mean()\n",
    "v = mean.values\n",
    "v = v.reshape(len(v),1)\n",
    "ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "print ratio_df\n",
    "\n",
    "\n",
    "# compared to dropping feature\n",
    "print '----------------------------------------------------------------'\n",
    "print 'LogReg perturbed data (DROPPING disc. variable):'\n",
    "rf = LogisticRegression()\n",
    "dft = pd.get_dummies(df_train_new[X_features])\n",
    "rf.fit(dft,df_train_new[Y_features])\n",
    "print 'Dropping D train performance: '\n",
    "print rf.score(dft,df_train[Y_features])\n",
    "\n",
    "df_train_pred = df_train_new\n",
    "df_train_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print df_train_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "dft = pd.get_dummies(df_test_new[X_features])\n",
    "print 'Dropping D test performance: '\n",
    "print rf.score(dft,df_test_new[Y_features])\n",
    "print 'Test classification result:'\n",
    "# save performance\n",
    "df_test_pred = df_test_new\n",
    "df_test_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print df_test_pred.groupby(D_features)['pred'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "RandForrest original data (with disc. variable):\n",
      "Train performance: (original dataset)\n",
      "0.802979115479\n",
      "Test performance (original dataset): \n",
      "0.807922616306\n",
      "Test classification result:\n",
      "Gender\n",
      " Female    0.110243\n",
      " Male      0.305952\n",
      "Name: pred, dtype: float64\n",
      "----------------------------------------------------------------\n",
      "RandForrest on perturbed data:\n",
      "Train performance (pert. dataset): \n",
      "0.772688882064\n",
      "Gender\n",
      " Female    0.254944\n",
      " Male      0.269238\n",
      "Name: pred, dtype: float64\n",
      "Train discrimination ratios result:\n",
      "Gender     Female      Male\n",
      "Gender                     \n",
      " Female  1.000000  0.946909\n",
      " Male    1.056068  1.000000\n",
      "Perturbed test performance when scored on original test y variable: \n",
      "0.739137110395\n",
      "Test classification result:\n",
      "Gender\n",
      " Female    0.344436\n",
      " Male      0.268964\n",
      "Name: pred, dtype: float64\n",
      "Test discrimination ratios result:\n",
      "Gender     Female      Male\n",
      "Gender                     \n",
      " Female  1.000000  1.280604\n",
      " Male    0.780882  1.000000\n",
      "Test discrimination value:\n",
      "0.280604008878\n",
      "----------------------------------------------------------------\n",
      "RandForrest original data (DROPPING disc. variable):\n",
      "Dropping D train performance: \n",
      "0.78804514742\n",
      "Gender\n",
      " Female    0.214307\n",
      " Male      0.256330\n",
      "Name: pred, dtype: float64\n",
      "Train discrimination ratios result:\n",
      "Gender     Female     Male\n",
      "Gender                    \n",
      " Female  1.000000  0.83606\n",
      " Male    1.196086  1.00000\n",
      "Dropping D test performance: \n",
      "0.787041302011\n",
      "Test classification result:\n",
      "Gender\n",
      " Female    0.214463\n",
      " Male      0.254806\n",
      "Name: pred, dtype: float64\n",
      "Test discrimination ratios result:\n",
      "Gender    Female      Male\n",
      "Gender                    \n",
      " Female  1.00000  0.841673\n",
      " Male    1.18811  1.000000\n",
      "----------------------------------------------------------------\n",
      "RandForrest perturbed data (DROPPING disc. variable):\n",
      "Dropping D train performance: \n",
      "0.783015970516\n",
      "Gender\n",
      " Female    0.169052\n",
      " Male      0.228041\n",
      "Name: pred, dtype: float64\n",
      "Dropping D test performance: \n",
      "0.741286657454\n",
      "Test classification result:\n",
      "Gender\n",
      " Female    0.326303\n",
      " Male      0.282545\n",
      "Name: pred, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# original performance on train data\n",
    "print '----------------------------------------------------------------'\n",
    "print 'RandForrest original data (with disc. variable):'\n",
    "rf = RandomForestClassifier()\n",
    "dft = pd.get_dummies(df_train[D_features+X_features])\n",
    "rf.fit(dft,df_train[Y_features])\n",
    "print 'Train performance: (original dataset)'\n",
    "print rf.score(dft,df_train[Y_features])\n",
    "\n",
    "# df_train_pred = df_train\n",
    "# df_train_pred['pred'] = rf.predict(dft)\n",
    "\n",
    "# # prediction per class\n",
    "# print df_train_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "dft = pd.get_dummies(df_test[D_features+X_features])\n",
    "print 'Test performance (original dataset): '\n",
    "print rf.score(dft,df_test[Y_features])\n",
    "\n",
    "print 'Test classification result:'\n",
    "# save performance\n",
    "df_test_pred = df_test\n",
    "df_test_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print df_test_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "\n",
    "\n",
    "print '----------------------------------------------------------------'\n",
    "print 'RandForrest on perturbed data:'\n",
    "\n",
    "# performance on perturbed train data\n",
    "rf = RandomForestClassifier()\n",
    "dft = pd.get_dummies(df_train_new[D_features+X_features])\n",
    "rf.fit(dft,df_train_new[Y_features])\n",
    "print 'Train performance (pert. dataset): '\n",
    "print rf.score(dft,df_train_new[Y_features])\n",
    "\n",
    "df_train_pred = df_train_new\n",
    "df_train_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "print df_train_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "print 'Train discrimination ratios result:'\n",
    "mean = df_train_pred.groupby(D_features)['pred'].mean()\n",
    "v = mean.values\n",
    "v = v.reshape(len(v),1)\n",
    "ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "print ratio_df\n",
    "\n",
    "# performance on perturbed train data compared to original train data\n",
    "#rf = RandomForestClassifier()\n",
    "#dft = pd.get_dummies(df_train_new[D_features+X_features])\n",
    "#rf.fit(dft,df_train_new[Y_features])\n",
    "dft = pd.get_dummies(df_test_new[D_features+X_features])\n",
    "print 'Perturbed test performance when scored on original test y variable: '\n",
    "print rf.score(dft,df_test[Y_features])\n",
    "\n",
    "dft = pd.get_dummies(df_test_new[D_features+X_features])\n",
    "# save performance\n",
    "df_test_pred = df_test_new\n",
    "df_test_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print 'Test classification result:'\n",
    "print df_test_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "# test discrimination ratios\n",
    "# This is what pyhgd will look like for y=1\n",
    "print 'Test discrimination ratios result:'\n",
    "mean = df_test_pred.groupby(D_features)['pred'].mean()\n",
    "v = mean.values\n",
    "v = v.reshape(len(v),1)\n",
    "ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "print ratio_df\n",
    "\n",
    "ratio_df_arr=np.asarray(np.abs(1-ratio_df))\n",
    "print 'Test discrimination value:'\n",
    "print np.amax(ratio_df_arr)\n",
    "\n",
    "\n",
    "# compared to dropping feature\n",
    "print '----------------------------------------------------------------'\n",
    "print 'RandForrest original data (DROPPING disc. variable):'\n",
    "rf = RandomForestClassifier()\n",
    "dft = pd.get_dummies(df_train[X_features])\n",
    "rf.fit(dft,df_train[Y_features])\n",
    "print 'Dropping D train performance: '\n",
    "print rf.score(dft,df_train[Y_features])\n",
    "\n",
    "df_train_pred = df_train\n",
    "df_train_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print df_train_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "print 'Train discrimination ratios result:'\n",
    "mean = df_train_pred.groupby(D_features)['pred'].mean()\n",
    "v = mean.values\n",
    "v = v.reshape(len(v),1)\n",
    "ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "print ratio_df\n",
    "\n",
    "dft = pd.get_dummies(df_test[X_features])\n",
    "print 'Dropping D test performance: '\n",
    "print rf.score(dft,df_test[Y_features])\n",
    "print 'Test classification result:'\n",
    "# save performance\n",
    "df_test_pred = df_test\n",
    "df_test_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print df_test_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "print 'Test discrimination ratios result:'\n",
    "mean = df_test_pred.groupby(D_features)['pred'].mean()\n",
    "v = mean.values\n",
    "v = v.reshape(len(v),1)\n",
    "ratio_df = pd.DataFrame(v/v.transpose(),index=mean.index,columns=mean.index )\n",
    "print ratio_df\n",
    "\n",
    "\n",
    "\n",
    "# compared to dropping feature\n",
    "print '----------------------------------------------------------------'\n",
    "print 'RandForrest perturbed data (DROPPING disc. variable):'\n",
    "rf = RandomForestClassifier()\n",
    "dft = pd.get_dummies(df_train_new[X_features])\n",
    "rf.fit(dft,df_train_new[Y_features])\n",
    "print 'Dropping D train performance: '\n",
    "print rf.score(dft,df_train[Y_features])\n",
    "\n",
    "df_train_pred = df_train_new\n",
    "df_train_pred['pred'] = rf.predict(dft)\n",
    "\n",
    "# prediction per class\n",
    "print df_train_pred.groupby(D_features)['pred'].mean()\n",
    "\n",
    "dft = pd.get_dummies(df_test_new[X_features])\n",
    "print 'Dropping D test performance: '\n",
    "print rf.score(dft,df_test_new[Y_features])\n",
    "print 'Test classification result:'\n",
    "# save performance\n",
    "df_test_pred = df_test_new\n",
    "df_test_pred['pred'] = rf.predict_proba(dft)[:,1]\n",
    "\n",
    "# prediction per class\n",
    "print df_test_pred.groupby(D_features)['pred'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age (decade)</th>\n",
       "      <th>Education Years</th>\n",
       "      <th>Income</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income Binary</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22407</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.228708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.288911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23057</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30134</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age (decade) Education Years  Income   Gender  Income Binary      pred\n",
       "22407           40               9    >50K     Male              1  0.228708\n",
       "3685            50               9   <=50K     Male              0  0.288911\n",
       "23057           40               9   <=50K   Female              0  0.228708\n",
       "30134           40               9   <=50K     Male              0  0.228708\n",
       "15912           20               9   <=50K     Male              0  0.040701"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age (decade)</th>\n",
       "      <th>Education Years</th>\n",
       "      <th>Income</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income Binary</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22407</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>&gt;50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>0.227629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.285255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23057</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0.227629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30134</th>\n",
       "      <td>40</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.227629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15912</th>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>&lt;=50K</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age (decade) Education Years  Income   Gender  Income Binary      pred\n",
       "22407           40               9    >50K     Male              1  0.227629\n",
       "3685            50               9   <=50K     Male              0  0.285255\n",
       "23057           40               9   <=50K   Female              0  0.227629\n",
       "30134           40               9   <=50K     Male              0  0.227629\n",
       "15912           20               9   <=50K     Male              0  0.042737"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
